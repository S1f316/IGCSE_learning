
#!/usr/bin/env python3
"""
ä» Excel æ–‡ä»¶æ‰¹é‡å¯¼å…¥ç³»ç»Ÿå•è¯åˆ°æ•°æ®åº“ï¼Œå¹¶ä¸ºæ‰€æœ‰ç”¨æˆ·åˆ›å»ºç¼ºå¤±çš„å¡ç‰‡çŠ¶æ€ã€‚

ç”¨æ³•ï¼š
    python import_word_list.py /path/to/Cleaned_Word_List.xlsx

å¦‚æœä¸æä¾›è·¯å¾„ï¼Œè„šæœ¬ä¼šä½¿ç”¨é»˜è®¤è·¯å¾„ï¼š
    ~/Desktop/0580è¾…å¯¼è½¯ä»¶/å•è¯æœ¬/Cleaned_Word_List.xlsx

ä¾èµ–ï¼špandasã€openpyxl (å·²åœ¨ requirements.txt ä¸­åˆ—å‡º)
"""
import os
import sys
from pathlib import Path
from typing import Union
import re  # ç”¨äºè§£æ unit ç¼–å·
from datetime import datetime

import pandas as pd

# è®¾ç½®ç¯å¢ƒå˜é‡ä»¥ç¡®ä¿ä½¿ç”¨æ•°æ®åº“
os.environ.setdefault("USE_DATABASE", "true")

# é¡¹ç›®å†…å¯¼å…¥ï¼ˆç¡®ä¿è„šæœ¬å¯å•ç‹¬è¿è¡Œï¼‰
from models.database import (
    get_db_session,
    initialize_db,
    SystemCard,
    User,
    UserCardState,
)

# ç¡®ä¿è¡¨å­˜åœ¨
initialize_db()

DEFAULT_EXCEL_PATH = (
    Path.home()
    / "Desktop"
    / "0580è¾…å¯¼è½¯ä»¶"
    / "å•è¯æœ¬"
    / "Cleaned_Word_List.xlsx"
)


def import_from_excel(excel_path: Union[str, Path] = DEFAULT_EXCEL_PATH, overwrite: bool = False) -> int:
    """ä» Excel æ–‡ä»¶å¯¼å…¥ç³»ç»Ÿå¡ç‰‡åˆ°æ•°æ®åº“ã€‚

    å‚æ•°:
        excel_path: Excel æ–‡ä»¶è·¯å¾„
        overwrite  : True -> æ¸…ç©ºæ—§æ•°æ®åå…¨é‡å¯¼å…¥ï¼›False -> ä»…å¢é‡å¯¼å…¥ç¼ºå¤±å¡ç‰‡
    è¿”å›:
        æ–°å¢çš„ SystemCard æ•°é‡
    """

    excel_path = Path(excel_path)
    if not excel_path.exists():
        print(f"âŒ Excel æ–‡ä»¶ä¸å­˜åœ¨: {excel_path}")
        return 0

    print(f"ğŸ“– è¯»å– Excel: {excel_path}")
    df = pd.read_excel(excel_path)

    required_cols = [
        "Unit",
        "Word",
        "Part_of_speech",
        "Chinese_definition",
        "English_definition",
    ]
    if not all(col in df.columns for col in required_cols):
        print(f"âŒ ç¼ºå°‘å¿…è¦åˆ—ã€‚åº”åŒ…å«: {', '.join(required_cols)}")
        print(f"å®é™…åˆ—å: {', '.join(df.columns)}")
        return 0

    session = get_db_session()
    new_cards_count = 0
    try:
        if overwrite:
            print("ğŸ§¹ overwrite=True: æ¸…ç©º SystemCard ä¸ UserCardState â€¦")
            session.query(UserCardState).delete()
            session.query(SystemCard).delete()
            session.commit()

        cards_to_add: list[SystemCard] = []

        # è¾…åŠ©å‡½æ•°ï¼šç»Ÿä¸€å•å…ƒç¼–å·ï¼Œå…¼å®¹ "1"ã€"Unit 1"ã€"unit1" ç­‰å†™æ³•
        def normalize_unit(value: str) -> str:
            s = str(value).strip().lower()
            # æå–æ•°å­—éƒ¨åˆ†
            match = re.search(r"(\d+)", s)
            num = match.group(1) if match else s
            return f"unit{num}"

        for i, row in enumerate(df.itertuples(index=False), start=1):
            raw_unit = str(getattr(row, "Unit")).strip()
            unit_id = normalize_unit(raw_unit)
            word = str(getattr(row, "Word")).strip()
            pos = str(getattr(row, "Part_of_speech")).strip()
            zh = str(getattr(row, "Chinese_definition")).strip()
            en = str(getattr(row, "English_definition")).strip()

            if not unit_id or not word:
                continue

            meaning_parts: list[str] = []
            if pos:
                meaning_parts.append(f"ã€{pos}ã€‘")
            if zh:
                meaning_parts.append(zh)
            if en:
                meaning_parts.append(f"({en})")
            meaning = " ".join(meaning_parts)

            id_suffix = f"{i:03d}"
            card_id = f"{unit_id}_{id_suffix}"

            # å¢é‡æ¨¡å¼ï¼šå·²å­˜åœ¨åˆ™è·³è¿‡
            if not overwrite and session.get(SystemCard, card_id):
                continue

            cards_to_add.append(
                SystemCard(
                    id=card_id,
                    unit_id=unit_id,
                    front=word,
                    back=meaning,
                    created_at=datetime.now(),
                )
            )

        if cards_to_add:
            session.add_all(cards_to_add)
            session.commit()
            new_cards_count = len(cards_to_add)
            print(f"âœ… æ–°å¢ {new_cards_count} å¼ ç³»ç»Ÿå¡ç‰‡")
        else:
            print("â„¹ï¸ æ²¡æœ‰æ–°çš„ç³»ç»Ÿå¡ç‰‡éœ€è¦å¯¼å…¥")

        # ä¸ºæ‰€æœ‰ç”¨æˆ·è¡¥é½ç¼ºå¤±çš„å¡ç‰‡çŠ¶æ€
        users = session.query(User).all()
        for user in users:
            existing_ids = {
                s.card_id for s in session.query(UserCardState).filter_by(username=user.username)
            }
            new_states = [
                UserCardState(
                    username=user.username,
                    card_id=card.id,
                    is_viewed=False,
                    due_date=card.created_at,
                    learning_factor=1.0,
                    is_user_card=False,
                )
                for card in cards_to_add
                if card.id not in existing_ids
            ]
            if new_states:
                session.add_all(new_states)
        session.commit()
        if cards_to_add:
            print("âœ… ç”¨æˆ·å¡ç‰‡çŠ¶æ€è¡¥é½å®Œæˆï¼")
        return new_cards_count
    except Exception as e:
        session.rollback()
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return 0
    finally:
        session.close()


# -------------------- CLI --------------------

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Import word list from Excel into database")
    parser.add_argument("--path", "-p", help="Excel æ–‡ä»¶è·¯å¾„", default=str(DEFAULT_EXCEL_PATH))
    parser.add_argument("--overwrite", "-o", action="store_true", help="æ¸…ç©ºæ—§æ•°æ®åå…¨é‡å¯¼å…¥")
    args = parser.parse_args()

    added = import_from_excel(args.path, args.overwrite)
    print(f"å®Œæˆï¼æ–°å¢ {added} å¼ å¡ç‰‡ã€‚") 